# Use Docker Model Runner
OPENAI_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/

# Disable streaming when using tools, for llama.cpp and Docker Model Runner
OPENAI_DISABLE_STREAMING=true

# Define the default model to use: qwen, 14B, coder variant
OPENAI_MODEL=eunomie/qwen2.5-coder-14b-instruct:q5_k_m

