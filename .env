# Use Docker Model Runner
OPENAI_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/

# Disable streaming when using tools, for llama.cpp and Docker Model Runner
OPENAI_DISABLE_STREAMING=true

# Define the default model to use: destral-small from Mistral AI
OPENAI_MODEL=eunomie/devstral-small-2505:q4_k_m